{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"mount_file_id":"1qxJoC9xPzOAbI766cJF2ocqPYTQKL2u6","authorship_tag":"ABX9TyOM01geCuvmmY6UtVIQWeiP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["import pandas as pd, nltk,re"],"metadata":{"id":"pQHslbXgH9ks"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from nltk.corpus import stopwords\n","from nltk.stem.porter import PorterStemmer\n","from nltk.stem import WordNetLemmatizer as wnl\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split as tts\n","from sklearn.naive_bayes import MultinomialNB as mnb\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import confusion_matrix"],"metadata":{"id":"Tdkf4DjpIQCb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nltk.download('stopwords')\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')    # Dependencies"],"metadata":{"id":"yMbB7MuWJFJh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ps = PorterStemmer()      # histories - histori\n","lemmatizer = wnl()        # histories - history (makes meaningful stem word)"],"metadata":{"id":"Gc9PIjz4JTv6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["msgs = pd.read_csv('/content/drive/MyDrive/datasets/smsspamcollection/SMSSpamCollection',sep='\\t',names=['label','features'])\n","msgs.head()"],"metadata":{"id":"t5ox2vqhK6BP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["msgs['features'][1]"],"metadata":{"id":"S7fChwyJRAUu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["corpus = []\n","words = []\n","for i in range(0,len(msgs)):\n","  lematized_form = re.sub('[^a-zA-Z]',' ',msgs['features'][i])  # replace all with \" space \" except the words(a-z and A-Z)\n","  lematized_form = lematized_form.lower()\n","  lematized_form = lematized_form.split()  # converts a sentence to list of words\n","  # lemmatize those words which are not a stopword\n","  lematized_form = [lemmatizer.lemmatize(word) for word in lematized_form if word not in stopwords.words('english')] # list comprehension\n","  \n","  # to know the number of words we get totally from a corpus\n","  for word in lematized_form:\n","    words.append(word)\n","  \n","  #  join the lemmatized words and create the array of sentences\n","  lematized_form = ' '.join(lematized_form)\n","  corpus.append(lematized_form)"],"metadata":{"id":"swwVu7ijPdqg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(corpus)"],"metadata":{"id":"95TAvzWfbrZN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cv = CountVectorizer(max_features=7120)   # for creating bag of words (numerical array representaion of a sentence)\n","x = cv.fit_transform(corpus).toarray()    # the sentence is now conveted to vector format\n","x.shape"],"metadata":{"id":"-dLfDe2Iab6P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y = pd.get_dummies(msgs['label'])\n","y = y.iloc[:,1].values    # to convert the labels into 1 or zero (0 : ham    ,   1 : spam)"],"metadata":{"id":"OLQiDJJHej7y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train,x_test,y_train,y_test = tts(x,y,test_size=0.20,random_state=25)"],"metadata":{"id":"uwGkQJpEfr3B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spam_detect_model = mnb()\n","spam_detect_model = spam_detect_model.fit(x_train , y_train)"],"metadata":{"id":"KR2qYFQrqMXD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_predict = spam_detect_model.predict(x_test)"],"metadata":{"id":"mQqBRNKirFKZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["accuracy = accuracy_score(y_test,y_predict)\n","accuracy"],"metadata":{"id":"Eu3pP1lnzjfG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","trial_dataset = np.array([x_test[100]])   # converts 1D array into 2D array for the prediction\n","trial_dataset.shape"],"metadata":{"id":"Dv-2eTHLsIdI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["p = spam_detect_model.predict(trial_dataset)\n","p"],"metadata":{"id":"RxRa-rHuyhd-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_test[100]"],"metadata":{"id":"r-ca05vfyro1"},"execution_count":null,"outputs":[]}]}